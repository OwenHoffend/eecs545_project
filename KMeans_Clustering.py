# -*- coding: utf-8 -*-
"""Kmeans_clustering.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17I-yHWfxk35fLTXzerPg2-EdmVhkRrvr

# Apply K-means to OSHA
"""

#Install packages 
#!pip install pyldavis

data_path = "your_own_path"
data_file_lst = os.listdir(data_path)

print("data_file_lst: {}".format(data_file_lst))

import pandas as pd
df = pd.read_excel(data_path+'tagged1000.xlsx')
print(len(df))

#df.head()

#df.dropna(subset=['summary.new', 'Tagged2'])

print("length of df is:",len(df))

#df.head(5)

summary = df['summary.new']
#summary.head()

print("Number of tags: {}".format(len(df.Tagged2.unique())))
frequency = df.Tagged2.value_counts()
print(frequency)

y_train_df = df['Tagged2']

"""## Preprocessing: Remove punctuation, lower alphabet"""

import re
summary = summary.apply(lambda x: x.strip())
# Remove punctuation
summary = summary.apply(lambda x: re.sub('[.,\!]', '', str(x)))
# Lower the letter
summary = summary.apply(lambda x: x.lower())
summary.head()

"""## TF-IDF vectorization"""

import nltk

nltk.download('stopwords')
from nltk.corpus import stopwords

import gensim
from gensim.utils import simple_preprocess

stop_words = stopwords.words('english')
extend_lst = ['from', '']

stop_words.extend(extend_lst)
print(stop_words)

summary_tolist = summary.tolist()
#summary_tolist

prep_sent_list = []

## Remove Stopwords
for i in range(len(summary_tolist)):
  sent = summary_tolist[i]
  empty_lst = []
  for word in sent.split(" "): 
    if word not in  stop_words:
      empty_lst.append(word)
  input_str = ' '.join(empty_lst)
  prep_sent_list.append(input_str)

#prep_sent_list

from sklearn.feature_extraction.text import TfidfVectorizer
vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(prep_sent_list)

tf_idf = pd.DataFrame(data = X.toarray(), columns=vectorizer.get_feature_names())

final_df = tf_idf

print("The total number of rows is: {}".format(final_df.shape[0]))

from sklearn.cluster import KMeans
def run_KMeans(max_number_k, data):
    max_number_k += 1
    result = dict()
    for i in range(2 , max_number_k):
        kmeans = KMeans(n_clusters = i
                               , init = 'k-means++'
                               , n_init = 12
                               , tol = 0.0005)

        result.update( {i : kmeans.fit(data)} )
        
    return result

kmeans = KMeans(n_clusters = 11
                               , init = 'k-means++'
                               , n_init = 10
                               , tol = 0.0001
                               #, n_jobs = -1
                               , random_state = 1
                               , algorithm = 'full').fit(final_df)
pred_labels = kmeans.labels_

pred_labels

value = 8
tag2idx = {t : i+8 for i,t in enumerate(list(set(y_train_df.values)))}
tag2idx

import numpy as np
y_train = y_train_df.to_numpy()
y_train_number = np.zeros(y_train.shape)
for i in range(y_train_number.shape[0]):
  y_train_number[i,] = tag2idx[y_train[i,]]
y_train_number = y_train_number.astype(int)
#print(y_train_number)

y_train = y_train_df.to_numpy()
#print(y_train)

new_df = pd.DataFrame(data = final_df)
new_df['label_kmeans'] = pred_labels
#new_df

# https://medium.com/@joel_34096/k-means-clustering-for-image-classification-a648f28bdc47
def retrieve_info(cluster_labels,y_train):
  #Allocates most probable label in each cluster using K-means clustering
  reference_labels = {}
  # For loop to run through each label of cluster label
  for i in range(len(np.unique(kmeans.labels_))):
    index = np.where(cluster_labels == i,1,0)
    num = np.bincount(y_train[index==1]).argmax()
    reference_labels[i] = num
  return reference_labels

import numpy as np
reference_labels = retrieve_info(pred_labels,y_train_number)
number_labels = np.random.rand(len(kmeans.labels_))
for i in range(len(kmeans.labels_)):
  number_labels[i] = reference_labels[kmeans.labels_[i]]

print(number_labels[:20].astype('int'))
print(y_train_number[:20])
print(y_train[:20])

## 다시 한 번 출처: https://medium.com/@joel_34096/k-means-clustering-for-image-classification-a648f28bdc47
from sklearn.metrics import accuracy_score
print(accuracy_score(number_labels,y_train_number))

from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

#groud truth: y_train_number

# print accuracy
print("Accuracy: ", accuracy_score(y_train_number, number_labels))

# print precision, recall, F1-score per each class/tag
print(classification_report(y_train_number, number_labels))

# print confusion matrix, check documentation for sorting rows/columns
print(confusion_matrix(y_train_number, number_labels))

print(tag2idx)







